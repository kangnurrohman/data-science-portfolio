{"metadata":{"kernelspec":{"display_name":"Python [conda env:data_science_projects]","language":"python","name":"conda-env-data_science_projects-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ainurrohmanbwx/future-sales-prediction-eda-5-algorithms?scriptVersionId=145169692\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Introduction\n\nIn the analysis of the \"Future Sales Prediction\" dataset, we conducted a comprehensive series of data analysis steps to create an accurate prediction model. The process began with Exploratory Data Analysis (EDA) to understand the dataset's characteristics. Subsequently, we performed data preprocessing, including outlier detection and handling using the winzoring technique, as well as data normalization using the min-max method. We then developed multiple models, including Linear Regression, Ridge Regression, Lasso Regression, Decision Tree, and Random Forest, all of which were evaluated through cross-validation. The model evaluation results revealed that Random Forest outperformed others, yielding an average Mean Squared Error (MSE) of 10.32%, Root Mean Squared Error (RMSE) of 8.09%, Mean Absolute Error (MAE) of 5.99%, and an R-squared value of 94.27%. Additionally, we conducted classic assumption tests, including tests for linearity, homoscedasticity, normality, multicollinearity, outliers, and independence, to ensure the validity of our model. These results provide in-depth insights into the quality of our prediction model and its relevance in the context of future sales forecasting.","metadata":{}},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('data/advertising.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Features explanation:\n\n- **TV**: this feature represents the amount of advertising budget spent on television media for a product or service in a certain period, for example in thousands of dollars (USD).\n- **Radio**: this feature represents the amount of advertising budget spent on radio media in the same period as TV.\n- **Newspaper**: this feature represents the amount of advertising budget spent in newspapers or print media in the same period as TV and Radio.\n- **Sales**: This feature represents product or service sales data in the same period as advertising expenditure on TV, Radio and Newspaper.","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe().T","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\n\nfigure = px.scatter(df, x='Sales', y='TV', size='TV', trendline='ols', title='Relationship Between Sales and TV Advertising')\nfigure.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\nfigure.update_layout(\n    xaxis_title='Sales',\n    yaxis_title='TV Advertising',\n    legend_title='TV Ad Size',\n    plot_bgcolor='white'\n)\nfigure.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = px.scatter(df, x='Sales', y='Newspaper', size='Newspaper', trendline='ols', title='Relationship Between Sales and Newspaper Advertising')\nfigure.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\nfigure.update_layout(\n    xaxis_title='Sales',\n    yaxis_title='Newspaper Advertising',\n    legend_title='Newspaper Ad Size',\n    plot_bgcolor='white'\n)\nfigure.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure = px.scatter(df, x='Sales', y='Radio', size='Radio', trendline='ols', title='Relationship Between Sales and Radio Advertising')\nfigure.update_traces(marker=dict(line=dict(width=2, color='DarkSlateGrey')), selector=dict(mode='markers'))\nfigure.update_layout(\n    xaxis_title='Sales',\n    yaxis_title='Radio Advertising',\n    legend_title='Radio Ad Size',\n    plot_bgcolor='white'\n)\nfigure.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the correlation\ncorrelation = df.corr()\nsales_correlation = correlation[\"Sales\"].sort_values(ascending=False)\n\n# Format and style the correlation values\nstyled_sales_correlation = sales_correlation.apply(lambda x: f'{x:.2f}')\nstyled_sales_correlation = styled_sales_correlation.reset_index()\nstyled_sales_correlation.columns = [\"Feature\", \"Correlation with Sales\"]\nstyled_sales_correlation.style.background_gradient(cmap='coolwarm', axis=0)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"markdown","source":"#### Outlier detection","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Create the box plot\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='TV', data=df, palette='Blues')\nplt.title('Box Plot of TV Advertising')\nplt.xlabel('TV Advertising Spending')\nplt.grid(axis='x', linestyle='--', alpha=0.6)\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the box plot\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='Radio', data=df, palette='Oranges')\nplt.title('Box Plot of Radio Advertising')\nplt.xlabel('Radio Advertising Spending')\nplt.grid(axis='x', linestyle='--', alpha=0.6)\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the box plot\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='Newspaper', data=df, palette='YlGnBu')\nplt.title('Box Plot of Newspaper Advertising')\nplt.xlabel('Newspaper Advertising Spending')\nplt.grid(axis='x', linestyle='--', alpha=0.6)\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are outliers in the Newspaper feature. To overcome this, we use the Winsorizing technique. Winsorizing is a technique that replaces outlier values with certain predetermined threshold values. We set the threshold value for the Newspaper feature at 2.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Ambang batas atas (threshold) untuk Winsorizing\nupper_threshold = 2 * np.std(df['Newspaper']) + np.mean(df['Newspaper'])\n\n# Menerapkan Winsorizing pada kolom 'Newspaper'\ndf['Newspaper'] = np.where(df['Newspaper'] > upper_threshold, upper_threshold, df['Newspaper'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the box plot\nplt.figure(figsize=(8, 6))\nsns.boxplot(x='Newspaper', data=df, palette='YlGnBu')\nplt.title('Box Plot of Newspaper Advertising')\nplt.xlabel('Newspaper Advertising Spending')\nplt.grid(axis='x', linestyle='--', alpha=0.6)\n\n# Show the plot\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Data normalization\n\nAt this stage, we use the min-max technique. Min-Max is a data preprocessing technique used in data analysis and machine learning to convert values in a dataset into a certain range, usually between 0 and 1.","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\n# Create a MinMaxScaler object\nscaler = MinMaxScaler()\n\n# Columns to be normalized (e.g., TV, Radio, Newspaper)\ncolumns_to_normalize = ['TV', 'Radio', 'Newspaper']\n\n# Apply Min-Max normalization to the selected columns\ndf[columns_to_normalize] = scaler.fit_transform(df[columns_to_normalize])\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling and Evaluation\n\nAt the modeling stage, we use 5 algorithms for comparison, namely Linear Regression, Ridge Regression, Lasso Regression, Decision Tree, and Random Forest.\n\nAnd for evaluation using MSE, RMSE, MAE and R-Squared.","metadata":{}},{"cell_type":"code","source":"X = df[['TV', 'Radio', 'Newspaper']]\ny = df['Sales']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n# Performing 5-fold cross-validation (can be adjusted to the desired number of folds)\nnum_folds = 5\n\n# Function to perform cross-validation and calculate metrics in percentage\ndef perform_cross_validation(model, X, y, num_folds):\n    mse_scores = -cross_val_score(model, X, y, cv=num_folds, scoring='neg_mean_squared_error')\n    rmse_scores = np.sqrt(mse_scores)\n    mae_scores = -cross_val_score(model, X, y, cv=num_folds, scoring='neg_mean_absolute_error')\n    r2_scores = cross_val_score(model, X, y, cv=num_folds, scoring='r2')\n    \n    return mse_scores, rmse_scores, mae_scores, r2_scores","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, Ridge, Lasso\n\n# Linear Regression\nlinear_model = LinearRegression()\nlinear_mse, linear_rmse, linear_mae, linear_r2 = perform_cross_validation(linear_model, X, y, num_folds)\nprint(\"Linear Regression:\")\nprint(f\"Average MSE: {np.mean(linear_mse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average RMSE: {np.mean(linear_rmse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average MAE: {np.mean(linear_mae) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average R-squared: {np.mean(linear_r2) * 100:.2f}%\")\nprint(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ridge Regression\nridge_model = Ridge(alpha=1.0)  # You can adjust alpha as needed\nridge_mse, ridge_rmse, ridge_mae, ridge_r2 = perform_cross_validation(ridge_model, X, y, num_folds)\nprint(\"Ridge Regression:\")\nprint(f\"Average MSE: {np.mean(ridge_mse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average RMSE: {np.mean(ridge_rmse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average MAE: {np.mean(ridge_mae) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average R-squared: {np.mean(ridge_r2) * 100:.2f}%\")\nprint(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lasso Regression\nlasso_model = Lasso(alpha=1.0)  # You can adjust alpha as needed\nlasso_mse, lasso_rmse, lasso_mae, lasso_r2 = perform_cross_validation(lasso_model, X, y, num_folds)\nprint(\"Lasso Regression:\")\nprint(f\"Average MSE: {np.mean(lasso_mse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average RMSE: {np.mean(lasso_rmse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average MAE: {np.mean(lasso_mae) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average R-squared: {np.mean(lasso_r2) * 100:.2f}%\")\nprint(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\n# Decision Trees\ntree_model = DecisionTreeRegressor(max_depth=None, random_state=0)  # You can adjust parameters as needed\ntree_mse, tree_rmse, tree_mae, tree_r2 = perform_cross_validation(tree_model, X, y, num_folds)\nprint(\"Decision Trees:\")\nprint(f\"Average MSE: {np.mean(tree_mse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average RMSE: {np.mean(tree_rmse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average MAE: {np.mean(tree_mae) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average R-squared: {np.mean(tree_r2) * 100:.2f}%\")\nprint(\"\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Random Forest\nforest_model = RandomForestRegressor(n_estimators=100, random_state=0)  # You can adjust parameters as needed\nforest_mse, forest_rmse, forest_mae, forest_r2 = perform_cross_validation(forest_model, X, y, num_folds)\nprint(\"Random Forest:\")\nprint(f\"Average MSE: {np.mean(forest_mse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average RMSE: {np.mean(forest_rmse) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average MAE: {np.mean(forest_mae) / np.mean(y) * 100:.2f}%\")\nprint(f\"Average R-squared: {np.mean(forest_r2) * 100:.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Classic assumption test\n\nAt the classical assumption testing stage, 5 assumption tests are used, namely linearity test, homoscedasticity test, normality test, multicollinearity test, outliers test, and independent test.","metadata":{}},{"cell_type":"code","source":"import statsmodels.api as sm\nimport statsmodels.stats.api as sms\n\n# Adding a constant to the independent variables (intercept)\nX = sm.add_constant(X)\n\n# Fit the regression model\nmodel = sm.OLS(y, X).fit()\n\n# Residuals (model residuals)\nresiduals = model.resid","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 1: Linearity\n# You can check linearity using residual vs. fitted values plot\nimport matplotlib.pyplot as plt\nplt.scatter(model.fittedvalues, residuals)\nplt.xlabel(\"Fitted Values\")\nplt.ylabel(\"Residuals\")\nplt.title(\"Linearity Check\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 2: Homoskedasticity\n# You can check homoskedasticity using Breusch-Pagan test\n_, p_homo, _, _ = sms.het_breuschpagan(residuals, X)\nprint(f\"Homoskedasticity (Breusch-Pagan): p-value = {p_homo:.4f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 3: Independence (Serial Correlation)\n# You can check for serial correlation using Durbin-Watson test\nfrom statsmodels.stats.stattools import durbin_watson\ndw_stat = durbin_watson(residuals)\nprint(f\"Serial Correlation (Durbin-Watson): DW Statistic = {dw_stat:.2f}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 4: Normality\n# You can check normality using a normal probability plot (Q-Q plot)\nimport scipy.stats as stats\nfig, ax = plt.subplots(figsize=(6, 4))\n_, (__, ___, r) = stats.probplot(residuals, plot=ax, fit=True)\nax.get_lines()[0].set_markerfacecolor('C0')\nax.get_lines()[0].set_markersize(5.0)\nax.get_lines()[1].set_linewidth(3.0)\nplt.title(\"Normal Probability Plot\")\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 5: Multicollinearity\n# You can check multicollinearity using the Variance Inflation Factor (VIF)\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = pd.DataFrame()\nvif[\"Features\"] = X.columns\nvif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\nprint(\"Multicollinearity (VIF):\")\nprint(vif)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assumption 6: Outliers\n# You can check for outliers using the studentized residuals and the Cook's distance\nstudent_resid = model.get_influence().resid_studentized_internal\ncooks_d = model.get_influence().cooks_distance[0]\noutliers = pd.DataFrame({'Studentized Residuals': student_resid, \"Cook's Distance\": cooks_d})\noutliers.index = X.index\nprint(\"Outliers:\")\nprint(outliers[outliers['Studentized Residuals'].abs() > 2])  # You can adjust the threshold as needed","metadata":{},"execution_count":null,"outputs":[]}]}