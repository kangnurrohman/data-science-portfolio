{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kangnurrohman/polarity-determination-with-lstm?scriptVersionId=112064672\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-10T00:58:34.90234Z","iopub.execute_input":"2022-11-10T00:58:34.903089Z","iopub.status.idle":"2022-11-10T00:58:34.923108Z","shell.execute_reply.started":"2022-11-10T00:58:34.902996Z","shell.execute_reply":"2022-11-10T00:58:34.921967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Install Library","metadata":{}},{"cell_type":"code","source":"!pip install Sastrawi","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:58:41.641419Z","iopub.execute_input":"2022-11-10T00:58:41.641902Z","iopub.status.idle":"2022-11-10T00:58:51.565534Z","shell.execute_reply.started":"2022-11-10T00:58:41.641861Z","shell.execute_reply":"2022-11-10T00:58:51.563808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Library","metadata":{}},{"cell_type":"code","source":"import re\nimport tqdm\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom keras.models import load_model\nfrom nltk.tokenize import word_tokenize\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:58:56.172039Z","iopub.execute_input":"2022-11-10T00:58:56.172487Z","iopub.status.idle":"2022-11-10T00:58:58.434874Z","shell.execute_reply.started":"2022-11-10T00:58:56.172449Z","shell.execute_reply":"2022-11-10T00:58:58.433878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_excel('/kaggle/input/review-of-the-application-pln-mobile/review of the application PLN mobile.xlsx')\ndf.rename(columns = {'content':'review', 'score':'sentiment'}, inplace = True)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-11-10T00:59:01.629991Z","iopub.execute_input":"2022-11-10T00:59:01.63066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.sort_values(by='at', ascending=False)\ndf = df[['review', 'sentiment']]\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df = df.replace({'sentiment' : {1:'negative', 2:'negative', 3:'neutral', 4:'positive', 5: 'positive' }})\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sentiment.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#removing neutral\ndf = df[df.sentiment != \"neutral\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def remove_tweet_special(text):\n    # remove tab, new line, ans back slice\n    text = text.replace('\\\\t',\" \").replace('\\\\n',\" \").replace('\\\\u',\" \").replace('\\\\',\"\")\n    # remove non ASCII (emoticon, chinese word, .etc)\n    text = text.encode('ascii', 'replace').decode('ascii')\n    # remove mention, link, hashtag\n    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())\n    # remove incomplete URL\n    return text.replace(\"http://\", \" \").replace(\"https://\", \" \")\n\ndef remove_number(text):\n    return  re.sub(r\"\\d+\", \"\", text)\n\ndef remove_punctuation(text):\n    return text.translate(str.maketrans(\"\",\"\",string.punctuation))\n\ndef remove_whitespace_LT(text):\n    return text.strip()\n\ndef remove_whitespace_multiple(text):\n    return re.sub('\\s+',' ',text)\n\ndef remove_singl_char(text):\n    return re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)\n\ndef word_tokenize_wrapper(text):\n    return word_tokenize(text)\n\ndef stopwords_removal(words):\n    list_stopwords = nltk.corpus.stopwords.words('indonesian')\n    #list_stopwords = stopwords.words('indonesian')\n    #list_stopwords.extend([])\n    #txt_stopword = pd.read_csv(\"#\", names= [\"stopwords\"], header = None)\n    #list_stopwords.extend(txt_stopword[\"stopwords\"][0].split(' '))\n    return [word for word in words if word not in list_stopwords]\n\ndef stemmed_wrapper(term):\n    factory = StemmerFactory()\n    stemmer = factory.create_stemmer()\n    return stemmer.stem(term)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pre_process_corpus(docs):\n  norm_docs = []\n  for doc in tqdm.tqdm(docs):\n    #case folding\n    doc = doc.lower()\n    doc = doc.lower()\n    #tokenization\n    doc = remove_tweet_special(doc)\n    doc = remove_number(doc)\n    doc = remove_punctuation(doc)\n    doc = remove_whitespace_LT(doc)\n    doc = remove_whitespace_multiple(doc)\n    doc = remove_singl_char(doc)\n    doc = word_tokenize_wrapper(doc)\n    #filtering\n    doc = stopwords_removal(doc)\n    #Stemming for indonesian\n    #doc = stemmed_wrapper(doc)\n    norm_docs.append(doc)\n    \n  norm_docs = [\" \".join(word) for word in norm_docs]\n  return norm_docs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndf.review = pre_process_corpus(df.review)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Handling imbalance (Oversampling)","metadata":{}},{"cell_type":"code","source":"from sklearn.utils import resample\n# Separate majority and minority classes in training data for upsampling \ndata_majority = df[df['sentiment'] == 'positive']\ndata_minority = df[df['sentiment'] == 'negative']\n\nprint(\"majority class before upsample:\",data_majority.shape)\nprint(\"minority class before upsample:\",data_minority.shape)\n\n# Upsample minority class\ndata_minority_upsampled = resample(data_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples= data_majority.shape[0],    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_balance = pd.concat([data_majority, data_minority_upsampled])\n \n# Display new class counts\nprint(\"After upsampling\\n\",df_balance.sentiment.value_counts(),sep = \"\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting Data","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_balance.review, df_balance.sentiment, test_size=0.2, random_state=42)\nX_train.shape , X_test.shape, y_train.shape, y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data formatting","metadata":{}},{"cell_type":"code","source":"import keras\n\nt = keras.preprocessing.text.Tokenizer(oov_token='<UNK>')\n# fit the tokenizer on the documents\nt.fit_on_texts(X_train)\nt.word_index['<PAD>'] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequence","metadata":{}},{"cell_type":"code","source":"X_train  = t.texts_to_sequences(X_train)\nX_test = t.texts_to_sequences(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Vocabulary size={}\".format(len(t.word_index)))\nprint(\"Number of Documents={}\".format(t.document_count))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Sequence Normalization","metadata":{}},{"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pad dataset to a maximum review length in words\nimport tensorflow as tf\nX_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH)\nX_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH)\nX_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding Labels","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nnum_classes=2 # positive -> 1, negative -> 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = le.fit_transform(y_train)\ny_test = le.transform(y_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOCAB_SIZE = len(t.word_index)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build Model Architecture","metadata":{}},{"cell_type":"code","source":"EMBEDDING_DIM = 300 # dimension for dense embeddings for each token\nLSTM_DIM = 128 # total LSTM units\n\ninp = keras.layers.Input(shape=(MAX_SEQUENCE_LENGTH,))\nx = keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, trainable=True)(inp)\nx = keras.layers.CuDNNLSTM(LSTM_DIM, return_sequences=True)(x)\n#x = (keras.layers.LSTM(LSTM_DIM, return_sequences=True)(x)\nx = keras.layers.Dense(LSTM_DIM, activation='relu')(x)\nx = keras.layers.Dropout(rate=0.5)(x)\nx = keras.layers.Dense(LSTM_DIM, activation='relu')(x)\nx = keras.layers.Dropout(rate=0.5)(x)\n\noutp = keras.layers.Dense(1, activation='sigmoid')(x)\n# initialize the model\nmodel = keras.models.Model(inputs=inp, outputs=outp)\n\n# make the model parallel\n#model2 = tf.keras.utils.multi_gpu_model(model, gpus=2)\n    \nmodel.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(), metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Model","metadata":{}},{"cell_type":"code","source":"batch_size = 128\nepochs = 300\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\nmc = ModelCheckpoint('./best_model/best_model_lstm.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n# fit model\nhistory = model.fit(X_train, y_train,  batch_size=batch_size, shuffle=True, validation_split=0.1, epochs=epochs, verbose=1, callbacks=[es, mc])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Model Performance","metadata":{}},{"cell_type":"code","source":"saved_model = load_model('./best_model/best_model_lstm.h5')\ntrain_acc = saved_model.evaluate(X_train, y_train, verbose=1)\ntest_acc = saved_model.evaluate(X_test, y_test, verbose=1)\nprint('Train: %.2f%%, Test: %.2f%%' % (train_acc[1]*100, test_acc[1]*100))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# list all data in history\nprint(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"prediction_probs = model.predict(X_test, verbose=1).ravel()\npredictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}